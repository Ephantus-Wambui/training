# `nf-core/demo`

[`nf-core/demo`](https://nf-co.re/demo/) is a simple nf-core style pipeline for workshops and demonstrations.

It was created using the nf-core template and is designed to run and configure quickly.

<figure class="excalidraw">
--8<-- "docs/nf_customize/img/subway.excalidraw.svg"
</figure>

The [`nf-core/demo`](https://nf-co.re/demo/) pipeline consists of three processes:

-   ([`FASTQC`](https://www.bioinformatics.babraham.ac.uk/projects/fastqc/)): Read QC
-   ([`SEQTK_TRIM`](https://github.com/lh3/seqtk)): Trim low quality bases from FastQ files
-   ([`MULTIQC`](http://multiqc.info/)): Present QC for raw reads

[`nf-core/demo`](https://nf-co.re/demo/) takes a samplesheet that contains paths to fastq files as an input and will produce four output folders with a variety of logs and reports:

-   `fastqc/`
    -   `*_fastqc.html`: FastQC report containing quality metrics.
    -   `*_fastqc.zip`: Zip archive containing the FastQC report, tab-delimited data file and plot images.
-   `fq/`
    -   `*.fastp.html`: Trimmed fq files.
-   `multiqc/`
    -   `multiqc_report.html`: a standalone HTML file that can be viewed in your web browser.
    -   `multiqc_data/`: directory containing parsed statistics from the different tools used in the pipeline.
    -   `multiqc_plots/`: directory containing static images from the report in various formats.
-   `pipeline_info/`
    -   Reports generated by Nextflow
    -   Reports generated by nf-core
    -   Parameters file

You can view the code for this pipeline on the [`nf-core/demo` GitHub repository](https://github.com/nf-core/demo).

To help you understand the expectations for running an nf-core pipeline, they come with extensive documentation about its parameters, usage, and outputs.

The documentation for the `nf-core/demo` pipeline can be found [here](https://nf-co.re/demo/docs/usage).

## Your first `nf-core/demo` execution command

Before running any pipeline you will need to check if there are any parameters that are required.

You can view these on the parameters page of the pipeline.

By viewing the [parameters page of the `nf-core/demo` pipeline](https://nf-co.re/demo/dev/parameters), you can see that requires two parameters (`--input` and `--outdir`) to run.

![nf-core logo](img/demo-parameters.png)

Without these, the pipeline will not launch and nextflow will throw an error.

### `--input`

The `--input` parameter requires a path to comma-separated file containing information about the samples in the experiment.

```bash
--input 'path/to/samplesheet.csv'
```

The nf-core/demo usage documentation describes the required `--input` as a comma-separated file (`.csv`). The `.csv` file must contain 3 columns with the headers `sample`, `fastq_1`, and `fastq_2`.

The samplesheet file may consist of both single- and paired-end data and may look something like the one below.

```csv title="samplesheet.csv"
sample,fastq_1,fastq_2
SAMPLE1_PE,path/to/sample1_R1.fastq.gz,path/to/sample1_R2.fastq.gz
SAMPLE2_PE,path/to/sample2_R1.fastq.gz,path/to/sample2_R2.fastq.gz
SAMPLE3_SE,path/to/sample3_R1.fastq.gz,
```

The pipeline will auto-detect whether a sample is single- or paired-end and if a sample has been sequenced more than once using the information provided in the samplesheet.

!!! question "Exercise"

    Within the `data` folder there are three sets of paired-end reads for gut, liver, and lung samples. Create a samplesheet for this data.

    First, create a `.csv` file named `samplesheet.csv`:

    ```bash
    code samplesheet.csv
    ```

    Next, add the header line, and, for each sample, an id and the complete paths to the paired-end reads:

    ```csv title="samplesheet.csv"
    sample,fastq_1,fastq_2
    gut,/workspace/gitpod/nf-customize/data/gut_1.fq.gz,/workspace/gitpod/nf-customize/data/gut_2.fq.gz
    liver,/workspace/gitpod/nf-customize/data/liver_1.fq.gz,/workspace/gitpod/nf-customize/data/liver_2.fq.gz
    lung,/workspace/gitpod/nf-customize/data/lung_1.fq.gz,/workspace/gitpod/nf-customize/data/lung_2.fq.gz
    ```

    **Make sure you save this file in your working directory (`/workspace/gitpod/nf-customize/`)**

### `--outdir`

The `--output` parameter is used to name the output directory where the results will be saved. It takes a string as its input.

```bash
--output results
```

You do not need to create this folder before you run the pipeline.

!!! question "Exercise"

    Execute the `nf-core/demo` pipeline with your new samplesheet as an input and an output directory named `results`:

    ```bash
    nextflow run nf-core/demo --input samplesheet.csv --outdir results
    ```

As the software required to run each process is not available in the Gitpod environment this exercise is expected to fail.

```console
ERROR ~ Error executing process > 'NFCORE_DEMO:DEMO:SEQTK_TRIM (gut)'

Caused by:
  Process `NFCORE_DEMO:DEMO:SEQTK_TRIM (gut)` terminated with an error exit status (127)
<truncated>
```

Fortunately, nf-core pipelines come packed with directives for containers and environments that can be flexibly enabled using configuration profiles.

### `-profile`

Configuration files can contain the definition of one or more profiles. A profile is a set of configuration attributes that can be added to your execution command by using the `-profile` option.

```bash
-profile <profile name>
```

Configuration profiles are defined by using the special scope `profile`, which group the attributes that belong to the same profile using a common prefix. For example:

```console title="example.config"
process.cpus = 1

profiles {
  foo {
    process.memory = '2 GB'
  }

  bar {
    process.memory = '4 GB'
  }
}
```

nf-core pipelines come with a series of profiles for running the pipelines using different software (e.g., Docker, Singularity, and Conda).

Here, you will need to add the `singularity` profile to your execution command. Nextflow will download and enable Singularity software images to run each process.

!!! question "Exercise"

    Execute the command again, but this time with the singularity profile:

    ```bash
    nextflow run nf-core/demo --input samplesheet.csv --outdir results -profile singularity
    ```

    The `nf-core/demo` pipeline should now run successfully!

Every nf-core pipeline also comes with a `test` profile. This is a minimal set of configuration settings for the pipeline to run using a small test dataset that is hosted on the [nf-core/test-datasets](https://github.com/nf-core/test-datasets) repository.

The `test` profile can be very useful for performing a test run of nf-core pipeline on your infrastructure before using your own data. As the `test` profile is expected to run it can be used to help diagnose local issues before you scale up your analysis.

You should use the `test` profile to check the pipeline runs before analyzing your own data.

The `test` profile for `nf-core/demo` is shown below:

```groovy title="conf/test.config" linenums="1"
/*
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Nextflow config file for running minimal tests
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~
    Defines input files and everything required to run a fast and simple pipeline test.

    Use as follows:
        nextflow run nf-core/demo -profile test,<docker/singularity> --outdir <OUTDIR>

----------------------------------------------------------------------------------------
*/

params {
    config_profile_name        = 'Test profile'
    config_profile_description = 'Minimal test dataset to check pipeline function'

    // Limit resources so that this can run on GitHub Actions
    max_cpus   = 2
    max_memory = '6.GB'
    max_time   = '6.h'

    // Input data
    input  = 'https://raw.githubusercontent.com/nf-core/test-datasets/viralrecon/samplesheet/samplesheet_test_illumina_amplicon.csv'

}
```

!!! note "Using multiple profiles"

    Multiple profiles can be specified in a comma-separated (`,`) list when you execute your command.

    The order of profiles is important as they will be read from left to right, for example:

    ```bash
    nextflow run nf-core/demo -r dev -profile test,singularity --outdir results
    ```

Note that the test profile for nf-core/demo has supplied an `input` but no `outdir`, meaning that an `outdir` must still be added to your execution command separately.

!!! question "Exercise"

    Execute `nf-core/demo` using the `test` and `singularity` profiles:

    ```bash
    nextflow run nf-core/demo -r dev -profile test,singularity --outdir results
    ```

If you're computer has internet access and one of Conda, Singularity, or Docker installed, you should be able to run any nf-core pipeline with the `test` profile and the respective profile "out of the box".

The `test` data profile will pull small test files directly from the `nf-core/test-datasets` GitHub repository and run it locally.

The `test` profile is an important control to check the pipeline is working as expected and is a great way to trial a pipeline.

Some pipelines have multiple test `profiles` for you to try.
